{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MK1Jl7nkLnPA",
        "outputId": "ac0c1a34-2632-4c84-a241-a27e9582dd77"
      },
      "outputs": [],
      "source": [
        "# gradient penalty is based on https://gist.github.com/cwkx/e85fefe8bffbe3b3598f8f582914eb12, which is released under the MIT licesne\n",
        "# model structure and classes based off https://github.com/Lornatang/WassersteinGAN_GP-PyTorch, which is released under the Apache-2.0 license\n",
        "# make sure you reference any code you have studied as above here\n",
        "\n",
        "# imports\n",
        "import math\n",
        "import numpy as np\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "from google.colab import files\n",
        "from torch import autograd\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "# hyperparameters\n",
        "batch_size  = 64\n",
        "n_channels  = 3\n",
        "latent_size = 512\n",
        "dataset = 'stl10'\n",
        "# dataset = 'mnist'\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ulyXUpjwpaWy"
      },
      "outputs": [],
      "source": [
        "# optional Google drive integration - this will allow you to save and resume training, and may speed up redownloading the dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKuo1Tmp2H1o"
      },
      "outputs": [],
      "source": [
        "opt = {\"lr\": 1e-4,\n",
        "       \"b1\": 0.5,\n",
        "       \"b2\": 0.9}\n",
        "N_CRITIC = 5\n",
        "N_SAMPLE = 100\n",
        "SAVEFIGS = True\n",
        "SAVEFOLDER = str(time.time())\n",
        "os.mkdir('drive/MyDrive/0WGAN-Outputs/'+SAVEFOLDER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bK383zeDM4Ac"
      },
      "outputs": [],
      "source": [
        "# helper function to make getting another batch of data easier\n",
        "def cycle(iterable):\n",
        "    while True:\n",
        "        for x in iterable:\n",
        "            yield x\n",
        "\n",
        "# you may use cifar10 or stl10 datasets\n",
        "if dataset == 'cifar10':\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        torchvision.datasets.CIFAR10('drive/My Drive/training/cifar10', train=True, download=True, transform=torchvision.transforms.Compose([\n",
        "            torchvision.transforms.Resize((batch_size,batch_size)),\n",
        "            torchvision.transforms.CenterCrop(batch_size),\n",
        "            torchvision.transforms.RandomHorizontalFlip(p=0.4),\n",
        "            torchvision.transforms.ToTensor(),\n",
        "            torchvision.transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
        "        ])),\n",
        "        shuffle=True, batch_size=batch_size, drop_last=True\n",
        "    )\n",
        "    class_names = ['airplane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "# stl10 has larger images which are much slower to train on. You should develop your method with CIFAR-10 before experimenting with STL-10\n",
        "if dataset == 'stl10':\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        torchvision.datasets.STL10('drive/My Drive/training/stl10', split='train+unlabeled', download=True, transform=torchvision.transforms.Compose([\n",
        "            torchvision.transforms.Resize((batch_size,batch_size)),\n",
        "            torchvision.transforms.CenterCrop(batch_size),\n",
        "            torchvision.transforms.RandomHorizontalFlip(p=0.4),\n",
        "            torchvision.transforms.ToTensor(),\n",
        "            torchvision.transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
        "        ])),\n",
        "    shuffle=True, batch_size=batch_size, drop_last=True)\n",
        "    train_iterator = iter(cycle(train_loader))\n",
        "    class_names = ['airplane', 'bird', 'car', 'cat', 'deer', 'dog', 'horse', 'monkey', 'ship', 'truck'] # these are slightly different to CIFAR-10\n",
        "\n",
        "if dataset == 'mnist':\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        torchvision.datasets.MNIST('drive/My Drive/training/mnist', train=True, download=True, transform=torchvision.transforms.Compose([\n",
        "            torchvision.transforms.Grayscale(3),\n",
        "            torchvision.transforms.Resize((batch_size,batch_size)),\n",
        "            torchvision.transforms.CenterCrop(batch_size),\n",
        "            torchvision.transforms.ToTensor()\n",
        "        ])),\n",
        "    shuffle=True, batch_size=batch_size, drop_last=True)\n",
        "    train_iterator = iter(cycle(train_loader))\n",
        "    class_names = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'] \n",
        "    n_channels = 1\n",
        "\n",
        "train_iterator = iter(cycle(train_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BtJs-qxHRLXz"
      },
      "outputs": [],
      "source": [
        "# let's view some of the training data\n",
        "plt.rcParams['figure.dpi'] = 175\n",
        "x,t = next(train_iterator)\n",
        "x,t = x.to(device), t.to(device)\n",
        "plt.grid(False)\n",
        "plt.imshow(torchvision.utils.make_grid(x).cpu().data.permute(0,2,1).contiguous().permute(2,1,0), cmap=plt.cm.binary)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qnjh12UbNFpV"
      },
      "source": [
        "**Define a WGAN-GP**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xeHiwrNVMPFf"
      },
      "outputs": [],
      "source": [
        "def grad_penalty(M, real_data, fake_data, lmbda=10):\n",
        "    alpha = torch.rand(real_data.size(0), 1, 1, 1).to(device)\n",
        "    interpolates = alpha * real_data + ((1 - alpha) * fake_data)\n",
        "    interpolates = interpolates.to(device)\n",
        "    interpolates = autograd.Variable(interpolates, requires_grad=True)\n",
        "    int_disc = M(interpolates)\n",
        "    gradients = torch.autograd.grad(outputs=int_disc, inputs=interpolates, grad_outputs=torch.ones(int_disc.size()).to(device), create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
        "    gradients = gradients.view(gradients.size(0), -1) \n",
        "    return ((gradients.norm(2, dim=1) - 1) ** 2).mean() * lmbda\n",
        "\n",
        "\n",
        "def weights_init(m):\n",
        "    if m.__class__.__name__.find(\"Conv\") != -1:\n",
        "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
        "    elif m.__class__.__name__.find(\"BatchNorm\") != -1:\n",
        "        torch.nn.init.normal_(m.weight, 1.0, 0.02)\n",
        "        torch.nn.init.zeros_(m.bias)\n",
        "    \n",
        "    \n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d(3, 96, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, True),\n",
        "            nn.Conv2d(96, 128, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2, True),\n",
        "            nn.Conv2d(128, 256, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2, True),\n",
        "            nn.Conv2d(256, 512, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2, True),\n",
        "            nn.Conv2d(512, 1, 4, 1, 0),\n",
        "        )\n",
        "\n",
        "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
        "        out = self.main(input)\n",
        "        out = torch.flatten(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.main = nn.Sequential(\n",
        "            nn.ConvTranspose2d(100, 512, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(128, 96, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(96),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(96, 3, 4, 2, 1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
        "        out = self.main(input)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WtcBjtu6NIKV"
      },
      "outputs": [],
      "source": [
        "reverse_mean = -0.5/0.5\n",
        "reverse_std = 1.0/0.5\n",
        "unnormalise = torchvision.transforms.Compose([ # to return images to correct space for display\n",
        "    # torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize(mean=(reverse_mean,reverse_mean,reverse_mean), std=(reverse_std,reverse_std,reverse_std))\n",
        "])\n",
        "\n",
        "generator = Generator().to(device)\n",
        "discriminator = Discriminator().to(device)\n",
        "\n",
        "generator = generator.apply(weights_init)\n",
        "discriminator = discriminator.apply(weights_init)\n",
        "\n",
        "optimiser_g = torch.optim.Adam(generator.parameters(), lr=opt['lr'], betas=(opt['b1'], opt['b2']))\n",
        "optimiser_d = torch.optim.Adam(discriminator.parameters(), lr=opt['lr'], betas=(opt['b1'], opt['b2']))\n",
        "\n",
        "discriminator.train()\n",
        "generator.train()\n",
        "\n",
        "epoch=0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1UBl0PJjY-f"
      },
      "source": [
        "**Main training loop**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kb5909Y8D_zx"
      },
      "outputs": [],
      "source": [
        "  # training loop, you will want to train for more than 10 here!\n",
        "epochs = 1000\n",
        "while (epoch<epochs):\n",
        "    \n",
        "    # array(s) for the performance measures\n",
        "    logs = {}\n",
        "    gen_loss_arr = np.zeros(0)\n",
        "    dis_loss_arr = np.zeros(0)\n",
        "    grad_pen_arr = np.zeros(0)\n",
        "\n",
        "    progress = tqdm(enumerate(train_loader), total=len(train_loader))\n",
        "    # for i in range(len(train_loader)):\n",
        "    for i, data in progress:\n",
        "        x = data[0].to(device)\n",
        "        noise = torch.randn(batch_size, 100, 1, 1, device=device)\n",
        "        # update discriminator...\n",
        "        discriminator.zero_grad()\n",
        "        x_out = discriminator(x)\n",
        "        x_d_err = torch.mean(x_out)\n",
        "        D_x = x_out.mean().item()\n",
        "\n",
        "        # Generate fake image\n",
        "        fake = generator(noise)\n",
        "        f_out = discriminator(fake.detach())\n",
        "        f_d_err = torch.mean(f_out)\n",
        "        D_G_z1 = f_out.mean().item()\n",
        "\n",
        "        # calc grad pen\n",
        "        gradient_penalty = grad_penalty(discriminator, x.data, fake.data)\n",
        "        errD = -x_d_err + f_d_err + gradient_penalty\n",
        "        errD.backward()\n",
        "\n",
        "        # update discriminator\n",
        "        optimiser_d.step()\n",
        "\n",
        "        if (i+1) % N_CRITIC == 0:\n",
        "            # update g every 2 steps\n",
        "            generator.zero_grad()\n",
        "            fake = generator(noise)\n",
        "            fake_out = discriminator(fake)\n",
        "            errG = -torch.mean(fake_out)\n",
        "            D_G_z2 = fake_out.mean().item()\n",
        "            errG.backward()\n",
        "            optimiser_g.step()\n",
        "\n",
        "\n",
        "            progress.set_description(f\"[{epoch + 1}/{epochs}][{i + 1}/{len(train_loader)}] \"\n",
        "                                                 f\"Loss_D: {errD.item():.6f} Loss_G: {errG.item():.6f} \"\n",
        "                                                 f\"D(x): {D_x:.6f} D(G(z)): {D_G_z1:.6f}/{D_G_z2:.6f}\")\n",
        "\n",
        "\n",
        "    # generate some examples of where we are up to\n",
        "    sample = generator(torch.randn(x.size(0), 100, 1, 1).to(device))\n",
        "    visualised_sample = unnormalise(sample)\n",
        "\n",
        "    # plot some examples\n",
        "    plt.rcParams['figure.dpi'] = 100\n",
        "    plt.grid(False)\n",
        "    plt.imshow(torchvision.utils.make_grid(visualised_sample[:8]).cpu().data.permute(0,2,1).contiguous().permute(2,1,0), cmap=plt.cm.binary)\n",
        "    if SAVEFIGS:\n",
        "        # fname = str(time.time())+\".jpg\"\n",
        "        plt.savefig('drive/MyDrive/0WGAN-Outputs/'+SAVEFOLDER+'/'+str(time.time())+'.jpg')\n",
        "        # plt.savefig(fname)\n",
        "    plt.show()\n",
        "    plt.pause(0.0001)\n",
        "    epoch = epoch+1\n",
        "\n",
        "    torch.save({'G':generator.state_dict(), 'optimiser_G':optimiser_g.state_dict(), 'D':discriminator.state_dict(), 'optimiser_D':optimiser_d.state_dict(), 'epoch':epoch}, 'drive/My Drive/training/save.chkpt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "liuFFKKE1pZp"
      },
      "outputs": [],
      "source": [
        "# now show a batch of data for the submission, right click and save the image for your report\n",
        "sample = unnormalise(generator(torch.randn(x.size(0), 100, 1, 1).to(device)))\n",
        "\n",
        "plt.rcParams['figure.dpi'] = 175\n",
        "plt.grid(False)\n",
        "plt.imshow(torchvision.utils.make_grid(sample).cpu().data.permute(0,2,1).contiguous().permute(2,1,0), cmap=plt.cm.binary)\n",
        "plt.savefig(\"generatedgrid.png\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBTf2_OvYJgB"
      },
      "outputs": [],
      "source": [
        "sample = generator(torch.randn(batch_size, 100, 1, 1).to(device))\n",
        "z = unnormalise(sample)\n",
        "\n",
        "# now show some interpolations (note you do not have to do linear interpolations as shown here, you can do non-linear or gradient-based interpolation if you wish)\n",
        "col_size = int(np.sqrt(batch_size))\n",
        "\n",
        "z0 = z[0:col_size].repeat(col_size,1,1,1) # z for top row\n",
        "z1 = z[batch_size-col_size:].repeat(col_size,1,1,1) # z for bottom row\n",
        "\n",
        "t = torch.linspace(0,1,col_size).unsqueeze(1).repeat(1,col_size).view(batch_size,1,1,1).to(device)\n",
        "\n",
        "lerp_z = (1-t)*z0 + t*z1 # linearly interpolate between two points in the latent space\n",
        "# lerp_g = A.decode(lerp_z) # sample the model at the resulting interpolated latents\n",
        "\n",
        "plt.rcParams['figure.dpi'] = 175\n",
        "plt.grid(False)\n",
        "plt.imshow(torchvision.utils.make_grid(lerp_z).cpu().data.permute(0,2,1).contiguous().permute(2,1,0), cmap=plt.cm.binary)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fHZF0cU4GcHE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HjHPwDAe-YoI"
      },
      "outputs": [],
      "source": [
        "# optional example code to save your training progress for resuming later if you authenticated Google Drive previously\n",
        "# torch.save({'G':generator.state_dict(), 'optimiser_G':optimiser_g.state_dict(), 'D':discriminator.state_dict(), 'optimiser_D':optimiser_d.state_dict(), 'epoch':epoch}, 'drive/My Drive/training/save.chkpt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nrCN7YQ5-2J8"
      },
      "outputs": [],
      "source": [
        "# # # optional example to resume training if you authenticated Google Drive previously\n",
        "# # params = torch.load('drive/My Drive/training/save.chkpt')\n",
        "# # params = torch.load('drive/My Drive/training/Copy of save.chkpt')\n",
        "# params = torch.load('./stl10.chkpt')\n",
        "\n",
        "# # params = torch.load('./save-2.chkpt')\n",
        "# generator.load_state_dict(params['G'])\n",
        "# optimiser_g.load_state_dict(params['optimiser_G'])\n",
        "# discriminator.load_state_dict(params['D'])\n",
        "# optimiser_d.load_state_dict(params['optimiser_D'])\n",
        "# epoch = params['epoch']\n",
        "\n",
        "# discriminator.train()\n",
        "# generator.train()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "STL10 31-3-22 WGAN-GP.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
